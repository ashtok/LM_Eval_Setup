====Next tasks to run====

lm_eval --model hf --model_args pretrained=mistralai/Mistral-7B-Instruct-v0.3 --tasks analogies_all,hypernymy_all,meronymy_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 4 --output_path ./results/

Models to Consider:


Google Gemma-3-1b-it

Done - lm_eval --model hf --model_args pretrained=google/gemma-3-1b-it --tasks analogies_high,analogies_low,analogies_medium,analogies_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=google/gemma-3-1b-it --tasks hypernymy_high,hypernymy_low,hypernymy_medium,hypernymy_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=google/gemma-3-1b-it --tasks meronymy_high,meronymy_low,meronymy_medium,meronymy_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=google/gemma-3-1b-it --tasks analogies_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=google/gemma-3-1b-it --tasks hypernymy_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 4 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=google/gemma-3-1b-it --tasks meronymy_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 4 --output_path ./results/


Qwen3-8B

Done - lm_eval --model hf --model_args pretrained=Qwen/Qwen3-8B --tasks analogies_high,analogies_low,analogies_medium,analogies_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=Qwen/Qwen3-8B --tasks hypernymy_high,hypernymy_low,hypernymy_medium,hypernymy_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=Qwen/Qwen3-8B --tasks meronymy_high,meronymy_low,meronymy_medium,meronymy_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=Qwen/Qwen3-8B --tasks analogies_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=Qwen/Qwen3-8B --tasks hypernymy_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=Qwen/Qwen3-8B --tasks meronymy_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/


Mistral-7B-Instruct-v0.3

Done - lm_eval --model hf --model_args pretrained=mistralai/Mistral-7B-Instruct-v0.3 --tasks analogies_high,analogies_low,analogies_medium,analogies_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=mistralai/Mistral-7B-Instruct-v0.3 --tasks hypernymy_high,hypernymy_low,hypernymy_medium,hypernymy_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=mistralai/Mistral-7B-Instruct-v0.3 --tasks meronymy_high,meronymy_low,meronymy_medium,meronymy_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done -lm_eval --model hf --model_args pretrained=mistralai/Mistral-7B-Instruct-v0.3 --tasks analogies_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=mistralai/Mistral-7B-Instruct-v0.3 --tasks hypernymy_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=mistralai/Mistral-7B-Instruct-v0.3 --tasks meronymy_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/


Google mT5-large

Done - lm_eval --model hf --model_args pretrained=google/mt5-large,use_safetensors=True --tasks analogies_high,analogies_low,analogies_medium,analogies_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=google/mt5-large,use_safetensors=True --tasks hypernymy_high,hypernymy_low,hypernymy_medium,hypernymy_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=google/mt5-large,use_safetensors=True --tasks meronymy_high,meronymy_low,meronymy_medium,meronymy_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=google/mt5-large,use_safetensors=True --tasks analogies_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=google/mt5-large,use_safetensors=True --tasks hypernymy_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=google/mt5-large,use_safetensors=True --tasks meronymy_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/


meta-llama/Llama-3.1-8B-Instruct

Done - lm_eval --model hf --model_args pretrained=meta-llama/Llama-3.1-8B-Instruct --tasks analogies_high,analogies_low,analogies_medium,analogies_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=meta-llama/Llama-3.1-8B-Instruct --tasks hypernymy_high,hypernymy_low,hypernymy_medium,hypernymy_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=meta-llama/Llama-3.1-8B-Instruct --tasks meronymy_high,meronymy_low,meronymy_medium,meronymy_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=meta-llama/Llama-3.1-8B-Instruct --tasks analogies_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=meta-llama/Llama-3.1-8B-Instruct --tasks hypernymy_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
Done - lm_eval --model hf --model_args pretrained=meta-llama/Llama-3.1-8B-Instruct --tasks meronymy_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/



lm_eval --model hf --model_args pretrained=google/mt5-large,use_safetensors=True --tasks analogies_all,hypernymy_all,meronymy_all --include_path ./lm_eval/tasks/NLP_JMU --device cpu --batch_size 2 --output_path ./results/ --limit 1


lm_eval --model hf --model_args pretrained=meta-llama/Llama-3.1-8B-Instruct --tasks hypernymy_mono,meronymy_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 4 --output_path ./results/results.json --write_out --log_samples



lm_eval --model hf --model_args pretrained=google/mt5-large,use_safetensors=True --tasks gloss_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/


New Tasks

Llama

lm_eval --model hf --model_args pretrained=meta-llama/Llama-3.1-8B-Instruct --tasks analogies_high,analogies_low,analogies_medium,analogies_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 4 --output_path ./results/
lm_eval --model hf --model_args pretrained=meta-llama/Llama-3.1-8B-Instruct --tasks hypernymy_high,hypernymy_low,hypernymy_medium,hypernymy_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 4 --output_path ./results/
lm_eval --model hf --model_args pretrained=meta-llama/Llama-3.1-8B-Instruct --tasks meronymy_high,meronymy_low,meronymy_medium,meronymy_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 4 --output_path ./results/
lm_eval --model hf --model_args pretrained=meta-llama/Llama-3.1-8B-Instruct --tasks gloss_high,gloss_low,gloss_medium,gloss_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 4 --output_path ./results/

lm_eval --model hf --model_args pretrained=meta-llama/Llama-3.1-8B-Instruct --tasks analogies_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 4 --output_path ./results/
lm_eval --model hf --model_args pretrained=meta-llama/Llama-3.1-8B-Instruct --tasks hypernymy_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 4 --output_path ./results/
lm_eval --model hf --model_args pretrained=meta-llama/Llama-3.1-8B-Instruct --tasks meronymy_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 4 --output_path ./results/
lm_eval --model hf --model_args pretrained=meta-llama/Llama-3.1-8B-Instruct --tasks gloss_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 4 --output_path ./results/

Mistral

lm_eval --model hf --model_args pretrained=mistralai/Mistral-7B-Instruct-v0.3 --tasks analogies_high,analogies_low,analogies_medium,analogies_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 4 --output_path ./results/
lm_eval --model hf --model_args pretrained=mistralai/Mistral-7B-Instruct-v0.3 --tasks hypernymy_high,hypernymy_low,hypernymy_medium,hypernymy_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 4 --output_path ./results/
lm_eval --model hf --model_args pretrained=mistralai/Mistral-7B-Instruct-v0.3 --tasks meronymy_high,meronymy_low,meronymy_medium,meronymy_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 4 --output_path ./results/
lm_eval --model hf --model_args pretrained=mistralai/Mistral-7B-Instruct-v0.3 --tasks gloss_high,gloss_low,gloss_medium,gloss_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 4 --output_path ./results/

lm_eval --model hf --model_args pretrained=mistralai/Mistral-7B-Instruct-v0.3 --tasks gloss_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 4 --output_path ./results/
lm_eval --model hf --model_args pretrained=mistralai/Mistral-7B-Instruct-v0.3 --tasks analogies_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 4 --output_path ./results/
lm_eval --model hf --model_args pretrained=mistralai/Mistral-7B-Instruct-v0.3 --tasks hypernymy_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 4 --output_path ./results/
lm_eval --model hf --model_args pretrained=mistralai/Mistral-7B-Instruct-v0.3 --tasks meronymy_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 4 --output_path ./results/

Qwen 3

lm_eval --model hf --model_args pretrained=Qwen/Qwen3-8B --tasks analogies_high,analogies_low,analogies_medium,analogies_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
lm_eval --model hf --model_args pretrained=Qwen/Qwen3-8B --tasks hypernymy_high,hypernymy_low,hypernymy_medium,hypernymy_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
lm_eval --model hf --model_args pretrained=Qwen/Qwen3-8B --tasks meronymy_high,meronymy_low,meronymy_medium,meronymy_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
lm_eval --model hf --model_args pretrained=Qwen/Qwen3-8B --tasks gloss_high,gloss_low,gloss_medium,gloss_mono --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/

lm_eval --model hf --model_args pretrained=Qwen/Qwen3-8B --tasks analogies_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
lm_eval --model hf --model_args pretrained=Qwen/Qwen3-8B --tasks gloss_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
lm_eval --model hf --model_args pretrained=Qwen/Qwen3-8B --tasks hypernymy_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
lm_eval --model hf --model_args pretrained=Qwen/Qwen3-8B --tasks meronymy_all --include_path ./lm_eval/tasks/NLP_JMU --device cuda --batch_size 2 --output_path ./results/
